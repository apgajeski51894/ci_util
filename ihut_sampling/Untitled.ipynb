{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ihut_sampling_csv_monadic.py\n",
    "import os\n",
    "import ba_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ds_util.qubole import run_hive, run_presto\n",
    "from ba_tools.utils import dump_to_excel\n",
    "from datetime import datetime, timedelta\n",
    "from functools import lru_cache\n",
    "from ba_tools.utils import id_input_validation\n",
    "import re\n",
    "from ds_util.qubole import run_presto\n",
    "import io\n",
    "from decipher.beacon import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and format screener data for sampling\n",
    "def get_screener_data(survey):\n",
    "\n",
    "    #Creates dataframe with all survey data\n",
    "    df = pd.read_csv('/Users/alex.gajeski/{survey}.csv'.format(survey=survey))\n",
    "\n",
    "    #Pulls out, renames, and combines key columns for balancing\n",
    "    email = df.loc[:, df.columns.str.contains('email')]\n",
    "    email.columns = ['email']\n",
    "    customer_id = df.loc[:, df.columns.str.contains('customer_id')]\n",
    "    customer_id.columns = ['customer_id']\n",
    "    first_name = df.loc[:, df.columns.str.contains('first_name')]\n",
    "    first_name.columns = ['first_name']\n",
    "    age_tier = df.loc[:, df.columns.str.contains('age_tier')]\n",
    "    age_tier.columns = ['age_tier']\n",
    "    gender = df.loc[:, df.columns.str.contains('gender')]\n",
    "    gender.columns = ['gender']\n",
    "    region = df.loc[:, df.columns.str.contains('region')]\n",
    "    region.columns = ['region']\n",
    "    ethnicity = df.loc[:, df.columns.str.contains('ethnicity')]\n",
    "    ethnicity.columns = ['ethnicity']\n",
    "    kids = df.loc[:, df.columns.str.contains('kids_in_hh')]\n",
    "    kids.columns = ['kids']\n",
    "    income = df.loc[:, df.columns.str.contains('income')]\n",
    "    income.columns = ['income']\n",
    "    frames = [email,customer_id,first_name,age_tier,gender,region,ethnicity,kids,income]\n",
    "    new_data = pd.concat(frames,axis=1)\n",
    "    new_data=new_data.dropna(axis=0)\n",
    "\n",
    "    #filter out respondents who selected prefer not to answer for income or ethnicity\n",
    "    new_data = new_data[new_data['income']!=9]\n",
    "    new_data = new_data[new_data['ethnicity']!=8]\n",
    "\n",
    "    new_data['ethnicity'].replace({6: \"Caucasian\", 1: \"Asian\",2: \"African American\",3: \"Hispanic\",4: \"Native American\",5: \"Native Hawiaan\", 7: \"Other\"},inplace=True)\n",
    "    new_data['ethnicity_group'] = new_data['ethnicity']\n",
    "    new_data['ethnicity_group'].replace({'Caucasian': \"Caucasian\",'Asian': \"Non-Caucasian\",'African American':\"Non-Caucasian\",'Hispanic':\"Non-Caucasian\",'Native American': \"Non-Caucasian\",'Native Hawiaan':\"Non-Caucasian\",'Other': \"Non-Caucasian\"},inplace=True)\n",
    "    new_data['kids'].replace({1: \"Kids\",2:\"No_kids\"}, inplace=True)\n",
    "    new_data['income'].replace({1: \"<$50K\",2: \"<$50K\",3: \"<$50K\",4: \"<$50K\",5: \"$50K-$100K\",6: \"$50K-$100K\",7: \"$100K+\",8: \"$100K+\"}, inplace=True)\n",
    "    new_data['age_tier'].replace({\"18-24\": \"18-34\",\"25-34\": \"18-34\",\"35-44\": \"35-54\",\"45-54\": \"35-54\",\"55-64\": \"55+\",\"65+\": \"55+\"}, inplace=True)\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_criteria(data,n_size,lim):\n",
    "    dd=data.groupby(['age_tier','region','kids','income','gender','ethnicity_group'],axis=0,as_index=True,dropna=True).count().reset_index()\n",
    "    dd['total']=pd.to_numeric(dd['email'],downcast='float')\n",
    "    dd['weight']=dd['total']/dd.total.sum()\n",
    "    weight = dd[['age_tier','region','kids','income','gender','ethnicity_group','total','weight']]\n",
    "    weight['sample_size'] = round(weight['weight']*n_size,0)\n",
    "    weight = weight[(weight['sample_size']*lim <= weight['total'])]\n",
    "    weight = weight[(weight['sample_size'] >= lim)].reset_index()\n",
    "    weight['key'] = weight['age_tier']+weight['region']+weight['kids']+weight['income']+weight['gender']+weight['ethnicity_group']\n",
    "\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_data_frames(weight,data):\n",
    "    df_dict={}\n",
    "    for index, row in weight.iterrows():\n",
    "        filtered = filtered_tables(df = data,\n",
    "                                   age_tier = row['age_tier'],\n",
    "                                   region = row['region'],\n",
    "                                   kids = row['kids'],\n",
    "                                   income = row['income'],\n",
    "                                   gender = row['gender'],\n",
    "                                   ethnicity_group = row['ethnicity_group'])\n",
    "        df_dict[row['key']]=filtered\n",
    "\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_tables(df,age_tier,region,kids,income,gender,ethnicity_group):\n",
    "\n",
    "    filtered = df[(df['age_tier'] == '{age_tier}'.format(age_tier=age_tier)) & (df['region'] == '{region}'.format(region=region)) & (df['kids']=='{kids}'.format(kids=kids)) & (df['income'] == '{income}'.format(income=income)) & (df['gender'] == '{gender}'.format(gender=gender))& (df['ethnicity_group'] == '{ethnicity_group}'.format(ethnicity_group=ethnicity_group))]\n",
    "\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_file(df_dict,weight,lim,n_size,data):\n",
    "    dict_keys=weight['key']\n",
    "    keys=dict_keys.to_frame(name='keys')\n",
    "    columns = ['email','first_name','customer_id','age_tier','gender','region','ethnicity','kids','income','ethnicity_group','try_first']\n",
    "    sample_list = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for index, row in keys.iterrows():\n",
    "        respondents = participants(keys=row['keys'],\n",
    "                          df_dict=df_dict,\n",
    "                          weight=weight,\n",
    "                          lim=lim)\n",
    "        sample_list=sample_list.append(respondents)\n",
    "\n",
    "    duplicates = pd.merge(data, sample_list, how='inner',left_on=['email'], right_on=['email'],left_index=True)\n",
    "    available_sample = data.drop(duplicates.index)\n",
    "\n",
    "    segments = sample_list.try_first.unique()\n",
    "    segments = pd.DataFrame(segments,columns=['segment'])\n",
    "\n",
    "    sample_file = sample_list\n",
    "\n",
    "    for index, row in segments.iterrows():\n",
    "        if (n_size - sum(sample_file.group == row['segment'])) > 0:\n",
    "            n = (n_size - sum(sample_file.group == row['segment']))\n",
    "            ns = available_sample.sample(n)\n",
    "            ns['try_first'] = row['segment']\n",
    "            available_sample = available_sample.drop(ns.index)\n",
    "            sample_file=sample_file.append(ns)\n",
    "\n",
    "    return sample_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participants(weight,df_dict,lim,keys):\n",
    "    df = df_dict['{keys}'.format(keys=keys)]\n",
    "    n_pre = weight[(weight['key']=='{keys}'.format(keys=keys))]\n",
    "    n = n_pre.sample_size.sum()\n",
    "    n = n.astype(np.int64)\n",
    "\n",
    "    columns = ['email','customer_id','first_name','age_tier','gender','region','ethnicity','kids','income','ethnicity_group','try_first']\n",
    "    sample_group = pd.DataFrame(columns=columns)\n",
    "    count=0\n",
    "    for i in range(lim):\n",
    "        participants = df.sample(n)\n",
    "        count += 1\n",
    "        participants['try_first'] = count\n",
    "        sample_group=sample_group.append(participants)\n",
    "        df=df.drop(participants.index)\n",
    "\n",
    "\n",
    "    return sample_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview(data,sample):\n",
    "    demo_dict={}\n",
    "    segments = sample.group.unique()\n",
    "    segments = pd.DataFrame(segments,columns=['segment'])\n",
    "    for index, row in segments.iterrows():\n",
    "        seg_data = sample[(sample['try_first']==row['segment'])]\n",
    "        demo_dict[row['segment']]=seg_data\n",
    "\n",
    "    demo_columns = ['age_tier','region','kids','gender','income','ethnicity']\n",
    "    demo_profiles=pd.DataFrame(demo_columns,columns=['demo_metric'])\n",
    "\n",
    "    combine = pd.Series()\n",
    "    for index, row in demo_profiles.iterrows():\n",
    "        cnt = (sample[row['demo_metric']].value_counts() / len(sample[row['demo_metric']]))\n",
    "        combine = combine.append(cnt)\n",
    "\n",
    "    tot_col = ['Total']\n",
    "    profile = pd.DataFrame(combine,columns=tot_col)\n",
    "\n",
    "    for k in demo_dict:\n",
    "        datas = demo_dict[k]\n",
    "        combine_data = pd.Series()\n",
    "        for index, row in demo_profiles.iterrows():\n",
    "            freq = (datas[row['demo_metric']].value_counts() / len(datas[row['demo_metric']]))\n",
    "            combine_data = combine_data.append(freq)\n",
    "        combine_data = pd.DataFrame(combine_data,columns=[k])\n",
    "        profile = profile.join(combine_data,how='inner')\n",
    "\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(sample_overview,sample):\n",
    "\n",
    "    tabs_data: list = []\n",
    "\n",
    "    tabs_data.append(sample)\n",
    "    tabs_data.append(sample_overview)\n",
    "\n",
    "\n",
    "    xlname = 'IHUT_Sample_File.xlsx'\n",
    "\n",
    "    sheet_names = [\"Sample Assignment\",\n",
    "                   \"Balancing Overview\"]\n",
    "\n",
    "    dump_to_excel(xlname, tabs_data, sheet_names=sheet_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_file(df_dict,weight,lim,n_size,data):\n",
    "    dict_keys=weight['key']\n",
    "    keys=dict_keys.to_frame(name='keys')\n",
    "    columns = ['email','first_name','customer_id','age_tier','gender','region','ethnicity','kids','income','ethnicity_group','try_first']\n",
    "    sample_list = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for index, row in keys.iterrows():\n",
    "        respondents = participants(keys=row['keys'],\n",
    "                          df_dict=df_dict,\n",
    "                          weight=weight,\n",
    "                          lim=lim)\n",
    "        sample_list=sample_list.append(respondents)\n",
    "\n",
    "    duplicates = pd.merge(data, sample_list, how='inner',left_on=['email'], right_on=['email'],left_index=True)\n",
    "    available_sample = data.drop(duplicates.index)\n",
    "\n",
    "    segments = sample_list.try_first.unique()\n",
    "    segments = pd.DataFrame(segments,columns=['segment'])\n",
    "\n",
    "    sample_file = sample_list\n",
    "\n",
    "    for index, row in segments.iterrows():\n",
    "        if (n_size - sum(sample_file.try_first == row['segment'])) > 0:\n",
    "            n = (n_size - sum(sample_file.try_first == row['segment']))\n",
    "            ns = available_sample.sample(n)\n",
    "            ns['try_first'] = row['segment']\n",
    "            available_sample = available_sample.drop(ns.index)\n",
    "            sample_file=sample_file.append(ns)\n",
    "\n",
    "    return sample_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participants(weight,df_dict,lim,keys):\n",
    "    df = df_dict['{keys}'.format(keys=keys)]\n",
    "    n_pre = weight[(weight['key']=='{keys}'.format(keys=keys))]\n",
    "    n = n_pre.sample_size.sum()\n",
    "    n = n.astype(np.int64)\n",
    "\n",
    "    columns = ['email','customer_id','first_name','age_tier','gender','region','ethnicity','kids','income','ethnicity_group','try_first']\n",
    "    sample_group = pd.DataFrame(columns=columns)\n",
    "    count=0\n",
    "    for i in range(lim):\n",
    "        participants = df.sample(n)\n",
    "        count += 1\n",
    "        participants['try_first'] = count\n",
    "        sample_group=sample_group.append(participants)\n",
    "        df=df.drop(participants.index)\n",
    "\n",
    "\n",
    "    return sample_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_second(sample,weight,p_eval,n_size,lim):\n",
    "    data = sample\n",
    "    products = list(range(1,lim+1))\n",
    "    grouped_dict = {}\n",
    "    for i in products:\n",
    "        d = date[data['try_first'] == i]\n",
    "        grouped_dict[[i]]=d\n",
    "    columns = ['email','customer_id','first_name','age_tier','gender','region','ethnicity','kids','income','ethnicity_group','try_first','try_second']   \n",
    "    try_2nd = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in range(1,lim+1):\n",
    "        p = list(range(1,lim+1))\n",
    "        df = grouped_dict[i]\n",
    "        group_filter = df.try_first.unique().sum()\n",
    "        p.remove(group_filter)\n",
    "        n=len(p)\n",
    "        split = len(df)/len(p)\n",
    "        \n",
    "        df.sample(frac=1)\n",
    "        n=df.sample(frac=1).reset_index().drop(columns=['index']).reset_index()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        respondents = try_second(keys=row['keys'],\n",
    "                          df_dict=df_dict,\n",
    "                          weight=weight,\n",
    "                          lim=lim)\n",
    "        sample_list=sample_list.append(respondents)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participants(group_dict,lim,keys):\n",
    "    df = df_dict['{keys}'.format(keys=keys)]\n",
    "    n_pre = weight[(weight['key']=='{keys}'.format(keys=keys))]\n",
    "    n = n_pre.sample_size.sum()\n",
    "    n = n.astype(np.int64)\n",
    "\n",
    "    columns = ['email','customer_id','first_name','age_tier','gender','region','ethnicity','kids','income','ethnicity_group','try_first']\n",
    "    sample_group = pd.DataFrame(columns=columns)\n",
    "    count=0\n",
    "    for i in range(lim):\n",
    "        participants = df.sample(n)\n",
    "        count += 1\n",
    "        participants['try_first'] = count\n",
    "        sample_group=sample_group.append(participants)\n",
    "        df=df.drop(participants.index)\n",
    "\n",
    "\n",
    "    return sample_group    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the csv file with the screener data? (this must be saved in your home directory; do not include .csv in the name)ctc_ihut_screener_sample\n",
      "How many sample groups are there? 3\n",
      "How many products will each participant be evaluating?1\n",
      "Is there a benchmark evaluated by everyone?: Enter yes or nono\n",
      "How participants would you like per group? (recommend adding 2-3 more than needed) 120\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_screener_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2d093b925f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-2d093b925f35>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbench\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Is there a benchmark evaluated by everyone?: Enter yes or no\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mn_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How participants would you like per group? (recommend adding 2-3 more than needed) \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_screener_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalancing_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_data_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_screener_data' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    survey = str(input(\"What is the name of the csv file with the screener data? (this must be saved in your home directory; do not include .csv in the name)\"))\n",
    "    lim = int(input(\"How many sample groups are there? \"))\n",
    "    p_eval = int(input(\"How many products will each participant be evaluating?\"))\n",
    "    bench = str(input(\"Is there a benchmark evaluated by everyone?: Enter yes or no\")).lower()\n",
    "    n_size = int(input(\"How participants would you like per group? (recommend adding 2-3 more than needed) \"))\n",
    "    data = pd.DataFrame(get_screener_data(survey))\n",
    "    weight = pd.DataFrame(balancing_criteria(data,n_size,lim))\n",
    "    df_dict = filtered_data_frames(weight,data)\n",
    "    sample = sample_file(df_dict,weight,lim,n_size,data)\n",
    "    sample['key'] = sample['age_tier']+sample['region']+sample['kids']+sample['income']+sample['gender']+sample['ethnicity_group']\n",
    "    append_key = sample\n",
    "    sample_overview = overview(data,sample)\n",
    "    exporting = export(sample_overview,sample)\n",
    "    print(\"DONE!!!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-355f44c7a592>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weight['sample_size'] = round(weight['weight']*n_size,0)\n"
     ]
    }
   ],
   "source": [
    "    data = pd.DataFrame(get_screener_data(survey))\n",
    "    weight = pd.DataFrame(balancing_criteria(data,n_size,lim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df_dict = filtered_data_frames(weight,data)\n",
    "    sample = sample_file(df_dict,weight,lim,n_size,data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-7e803a4b729e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           email first_name  customer_id age_tier gender  \\\n",
      "361           ahelke@hotmail.com     Amanda     0.622701    18-34      f   \n",
      "71              rb0902@yahoo.com     Rachel     0.241144    18-34      f   \n",
      "412  brittanyclingman@icloud.com   Brittany     0.387448    18-34      f   \n",
      "473   prettyinpink2904@gmail.com    chelsey     0.340553    18-34      f   \n",
      "244        alpmommy922@gmail.com     Carley     0.529440    18-34      f   \n",
      "..                           ...        ...          ...      ...    ...   \n",
      "393         couponaddict@att.net     Angela     0.736767    35-54      f   \n",
      "577         carrietm84@gmail.com     Carrie     0.521554    35-54      f   \n",
      "507        saramyles85@yahoo.com       sara     0.716282    35-54      f   \n",
      "874             kjtr17@yahoo.com    Kathryn     0.130250      55+      f   \n",
      "54        krislucas414@gmail.com    Kristen     0.131743    35-54      f   \n",
      "\n",
      "      region  ethnicity  kids      income ethnicity_group try_first  \\\n",
      "361  Midwest  Caucasian  Kids  $50K-$100K       Caucasian         1   \n",
      "71   Midwest  Caucasian  Kids  $50K-$100K       Caucasian         1   \n",
      "412  Midwest  Caucasian  Kids  $50K-$100K       Caucasian         1   \n",
      "473  Midwest  Caucasian  Kids  $50K-$100K       Caucasian         2   \n",
      "244  Midwest  Caucasian  Kids  $50K-$100K       Caucasian         2   \n",
      "..       ...        ...   ...         ...             ...       ...   \n",
      "393  Midwest  Caucasian  Kids  $50K-$100K       Caucasian         3   \n",
      "577    South  Caucasian  Kids       <$50K       Caucasian         3   \n",
      "507     West  Caucasian  Kids  $50K-$100K       Caucasian         3   \n",
      "874    South  Caucasian  Kids      $100K+       Caucasian         3   \n",
      "54     South  Caucasian  Kids  $50K-$100K       Caucasian         3   \n",
      "\n",
      "                                        key  \n",
      "361  18-34MidwestKids$50K-$100KfCaucasian_1  \n",
      "71   18-34MidwestKids$50K-$100KfCaucasian_1  \n",
      "412  18-34MidwestKids$50K-$100KfCaucasian_1  \n",
      "473  18-34MidwestKids$50K-$100KfCaucasian_2  \n",
      "244  18-34MidwestKids$50K-$100KfCaucasian_2  \n",
      "..                                      ...  \n",
      "393  35-54MidwestKids$50K-$100KfCaucasian_3  \n",
      "577         35-54SouthKids<$50KfCaucasian_3  \n",
      "507     35-54WestKids$50K-$100KfCaucasian_3  \n",
      "874          55+SouthKids$100K+fCaucasian_3  \n",
      "54     35-54SouthKids$50K-$100KfCaucasian_3  \n",
      "\n",
      "[360 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the name of the csv file with the screener data? (this must be saved in your home directory; do not include .csv in the name)ctc_ihut_screener_sample\n",
      "How many sample groups are there? 3\n",
      "How many products will each participant be evaluating?1\n",
      "Is there a benchmark evaluated by everyone?: Enter yes or nono\n",
      "How participants would you like per group? (recommend adding 2-3 more than needed) 120\n"
     ]
    }
   ],
   "source": [
    "    survey = str(input(\"What is the name of the csv file with the screener data? (this must be saved in your home directory; do not include .csv in the name)\"))\n",
    "    lim = int(input(\"How many sample groups are there? \"))\n",
    "    p_eval = int(input(\"How many products will each participant be evaluating?\"))\n",
    "    bench = str(input(\"Is there a benchmark evaluated by everyone?: Enter yes or no\")).lower()\n",
    "    n_size = int(input(\"How participants would you like per group? (recommend adding 2-3 more than needed) \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           email first_name  customer_id age_tier gender  \\\n",
      "361           ahelke@hotmail.com     Amanda     0.622701    18-34      f   \n",
      "71              rb0902@yahoo.com     Rachel     0.241144    18-34      f   \n",
      "412  brittanyclingman@icloud.com   Brittany     0.387448    18-34      f   \n",
      "473   prettyinpink2904@gmail.com    chelsey     0.340553    18-34      f   \n",
      "244        alpmommy922@gmail.com     Carley     0.529440    18-34      f   \n",
      "..                           ...        ...          ...      ...    ...   \n",
      "334           jciota93@gmail.com  Jenna-Lee     0.921320    18-34      f   \n",
      "499        married1225@yahoo.com      Laura     0.996061    18-34      f   \n",
      "602    holdermichaela1@gmail.com   michaela     0.713501    18-34      f   \n",
      "704          heanfra88@gmail.com    Heather     0.022965    18-34      f   \n",
      "844      emilytoby1013@gmail.com      Emily     0.575096    18-34      f   \n",
      "\n",
      "        region  ethnicity  kids      income ethnicity_group try_first  \\\n",
      "361    Midwest  Caucasian  Kids  $50K-$100K       Caucasian         1   \n",
      "71     Midwest  Caucasian  Kids  $50K-$100K       Caucasian         1   \n",
      "412    Midwest  Caucasian  Kids  $50K-$100K       Caucasian         1   \n",
      "473    Midwest  Caucasian  Kids  $50K-$100K       Caucasian         2   \n",
      "244    Midwest  Caucasian  Kids  $50K-$100K       Caucasian         2   \n",
      "..         ...        ...   ...         ...             ...       ...   \n",
      "334  Northeast  Caucasian  Kids       <$50K       Caucasian         3   \n",
      "499      South  Caucasian  Kids  $50K-$100K       Caucasian         3   \n",
      "602      South  Caucasian  Kids  $50K-$100K       Caucasian         3   \n",
      "704      South  Caucasian  Kids  $50K-$100K       Caucasian         3   \n",
      "844    Midwest  Caucasian  Kids       <$50K       Caucasian         3   \n",
      "\n",
      "                                        key  \n",
      "361  18-34MidwestKids$50K-$100KfCaucasian_1  \n",
      "71   18-34MidwestKids$50K-$100KfCaucasian_1  \n",
      "412  18-34MidwestKids$50K-$100KfCaucasian_1  \n",
      "473  18-34MidwestKids$50K-$100KfCaucasian_2  \n",
      "244  18-34MidwestKids$50K-$100KfCaucasian_2  \n",
      "..                                      ...  \n",
      "334     18-34NortheastKids<$50KfCaucasian_3  \n",
      "499    18-34SouthKids$50K-$100KfCaucasian_3  \n",
      "602    18-34SouthKids$50K-$100KfCaucasian_3  \n",
      "704    18-34SouthKids$50K-$100KfCaucasian_3  \n",
      "844       18-34MidwestKids<$50KfCaucasian_3  \n",
      "\n",
      "[71 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "cond = sample[(sample['age_tier'] == '18-34')]\n",
    "print(cond)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
