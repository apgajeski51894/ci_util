{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ba_tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ds_util.qubole import run_hive, run_presto\n",
    "from ba_tools.utils import dump_to_excel\n",
    "from datetime import datetime, timedelta\n",
    "from functools import lru_cache\n",
    "import shopper_analysis_queries as sql\n",
    "from ba_tools.utils import id_input_validation\n",
    "import re\n",
    "import ssl\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_presto(query, return_data=True, cluster='presto-consumer-insights-dev', **kwargs):\n",
    "    return run_presto(query=query, return_data=return_data, na_values='\\\\N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volumetrics(**params):\n",
    "\n",
    "    columns = ['segment','past_year_penn','current_year_penn','year_over_year_change_penn']\n",
    "    hh_penn = pd.DataFrame(columns=columns)\n",
    "\n",
    "    total_penn = ['total']\n",
    "    \n",
    "    py = params['py']\n",
    "    cy = params['cy']\n",
    "    total_pop_py = params['total_pop_py']\n",
    "    total_pop_cy = params['total_pop_cy']\n",
    "    seg_dict = params['seg_dict']\n",
    "    \n",
    "    py_penn = len(py.customer_id.unique())/total_pop_py\n",
    "    total_penn.append(py_penn)\n",
    "    cy_penn = len(cy.customer_id.unique())/total_pop_cy\n",
    "    total_penn.append(cy_penn)\n",
    "    change_penn = ((cy_penn-py_penn)/py_penn)\n",
    "    total_penn.append(change_penn)\n",
    "    penn_df = pd.DataFrame([total_penn],columns=columns)\n",
    "\n",
    "    hh_penn = hh_penn.append(penn_df,ignore_index=True)\n",
    "\n",
    "    for c,v in seg_dict.items():\n",
    "        for v in v:\n",
    "            p = [v]\n",
    "            df = py[py[c] == v]\n",
    "            df1 = cy[cy[c] == v]\n",
    "            py_penn = len(df.customer_id.unique())/total_pop_py\n",
    "            p.append(py_penn)\n",
    "            cy_penn = len(df1.customer_id.unique())/total_pop_cy\n",
    "            p.append(cy_penn)\n",
    "            change = ((cy_penn-py_penn)/py_penn)\n",
    "            p.append(change)\n",
    "            penn = pd.DataFrame([p],columns=columns)\n",
    "            hh_penn = hh_penn.append(penn,ignore_index=True)\n",
    "\n",
    "    cols = ['segment','past_year_avg_buy_rate','current_year_avg_buy_rate','past_year_median_buy_rate','current_year_idean_buy_rate','year_over_year_change_avg_buy_rate','year_over_year_change_median_buy_rate']\n",
    "    br = pd.DataFrame(columns=cols)\n",
    "\n",
    "    total_br = ['total']\n",
    "\n",
    "    py_br = py.groupby('customer_id').price.sum()\n",
    "    py_avg_br = py_br.mean()\n",
    "    py_med_br = py_br.median()\n",
    "    total_br.append(py_avg_br)\n",
    "    total_br.append(py_med_br)\n",
    "    cy_br = cy.groupby('customer_id').price.sum()\n",
    "    cy_avg_br = cy_br.mean()\n",
    "    cy_med_br = cy_br.median()\n",
    "    total_br.append(cy_avg_br)\n",
    "    total_br.append(cy_med_br)\n",
    "    avg_br_change = ((cy_avg_br-py_avg_br)/py_avg_br)\n",
    "    total_br.append(avg_br_change)\n",
    "    med_br_change = ((cy_med_br-py_med_br)/py_med_br)\n",
    "    total_br.append(med_br_change)\n",
    "    br_df = pd.DataFrame([total_br],columns=cols)\n",
    "\n",
    "    br = br.append(br_df,ignore_index=True)\n",
    "    for c,v in seg_dict.items():\n",
    "        for v in v:\n",
    "            p = [v]\n",
    "            df = py[py[c] == v]\n",
    "            df1 = cy[cy[c] == v]\n",
    "            py_br = df.groupby('customer_id').price.sum()\n",
    "            py_avg_br = py_br.mean()\n",
    "            py_med_br = py_br.median()\n",
    "            p.append(py_avg_br)\n",
    "            p.append(py_med_br)\n",
    "            cy_br = df1.groupby('customer_id').price.sum()\n",
    "            cy_avg_br = cy_br.mean()\n",
    "            cy_med_br = cy_br.median()\n",
    "            p.append(cy_avg_br)\n",
    "            p.append(cy_med_br)\n",
    "            avg_br_change = ((cy_avg_br-py_avg_br)/py_avg_br)\n",
    "            p.append(avg_br_change)\n",
    "            med_br_change = ((cy_med_br-py_med_br)/py_med_br)\n",
    "            p.append(med_br_change)\n",
    "            br_df = pd.DataFrame([p],columns=cols)\n",
    "\n",
    "            br = br.append(br_df,ignore_index=True)\n",
    "\n",
    "    volume_overview = hh_penn.merge(br,on='segment')\n",
    "    volume_overview['avg_previous_year_volume'] = volume_overview['past_year_penn']*volume_overview['past_year_avg_buy_rate']*125000000\n",
    "    volume_overview['avg_current_year_volume'] = volume_overview['current_year_penn']*volume_overview['current_year_avg_buy_rate']*125000000\n",
    "    volume_overview['avg_year_over_year_volume_change'] = ((volume_overview['avg_current_year_volume']-volume_overview['avg_previous_year_volume'])/volume_overview['avg_previous_year_volume'])\n",
    "    volume_overview['median_previous_year_volume'] = volume_overview['past_year_penn']*volume_overview['past_year_median_buy_rate']*125000000\n",
    "    volume_overview['median_current_year_volume'] = volume_overview['current_year_penn']*volume_overview['current_year_median_buy_rate']*125000000\n",
    "    volume_overview['median_year_over_year_volume_change'] = ((volume_overview['median_current_year_volume']-volume_overview['median_previous_year_volume'])/volume_overview['median_previous_year_volume'])\n",
    "\n",
    "    volume_overview = volume_overview.transpose.reset_index(drop=True)\n",
    "    return volume_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brand_loyalty(**params):\n",
    "    \n",
    "    ps_br = volume_overview.transpose.reset_index(drop=True)\n",
    "    brand_buy_rate = ps_br[['segment','current_year_avg_buy_rate','current_year_median_buy_rate']]\n",
    "    cols = ['segment','avg_brand_buy_rate','median_brand_buy_rate']\n",
    "    brand_buy_rate.columns = cols\n",
    "    columns = ['segment','avg_cat_buy_rate','median_cat_buy_rate','average_share','median_share']\n",
    "    category_buy_rate = pd.DataFrame(columns=columns)\n",
    "\n",
    "    cond = cy_cat.customer_id.isin(py.customer_id)\n",
    "    filtered_cat = cy_cat[cond]\n",
    "    l = ['total']\n",
    "    cat_br = filter_cat.groupby('customer_id').price.sum()\n",
    "    avg_cat_br = cat_br.mean()\n",
    "    med_cat_br = cat_br.median()\n",
    "    l.append(avg_cat_br)\n",
    "    l.append(med_cat_br)\n",
    "    avg_share = brand_buy_rate[brand_buy_rate['segment'] == 'total'].avg_brand_buy_rate.sum() / avg_cat_br\n",
    "    median_share = brand_buy_rate[brand_buy_rate['segment'] == 'total'].median_brand_buy_rate.sum() / med_cat_br\n",
    "    l.append(avg_share)\n",
    "    l.append(med_share)\n",
    "    cat_df = pd.DataFrame(l,columns=columns)\n",
    "    category_buy_rate = category_buy_rate.append(cat_df,ignore_index=True)\n",
    "\n",
    "    for c,v in seg_dict:\n",
    "        for v in v:\n",
    "            l = [v]\n",
    "            df = cy[cy[k] == v]\n",
    "            cond = cy_cat.customer_id.isin(df.customer_id)\n",
    "            filtered_cat = df[cond]\n",
    "            cat_br = filter_cat.groupby('customer_id').price.sum()\n",
    "            avg_cat_br = cat_br.mean()\n",
    "            med_cat_br = cat_br.median()\n",
    "            l.append(avg_cat_br)\n",
    "            l.append(med_cat_br)\n",
    "            avg_share = df[df['segment'] == v].avg_brand_buy_rate.sum() / avg_cat_br\n",
    "            median_share = df[df['segment'] == v].median_brand_buy_rate.sum() / med_cat_br\n",
    "            l.append(avg_share)\n",
    "            l.append(med_share)\n",
    "            cat_df = pd.DataFrame(l,columns=columns)\n",
    "            category_buy_rate = category_buy_rate.append(cat_df,ignore_index=True)\n",
    "\n",
    "    loyalty = brand_buy_rate.merge(category_buy_rate,on='segment')\n",
    "    loyalty = loyalty.transpose().reset_index(drop=True)\n",
    "\n",
    "    return loyalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial_repeat(**params):\n",
    "\n",
    "    df = cy\n",
    "    df['purchase_time_filled'] = pd.to_datetime(df.receipt_created_at)\n",
    "    df['delta'] = df.groupby('customer_id').purchase_time_filled.transform(pd.Series.diff)\n",
    "    df1 = df.groupby('customer_id').receipt_id.count().reset_index().groupby('receipt_id').customer_id.count().reset_index()\n",
    "    n = df1.customer_id.sum()\n",
    "    n = ['Base Size',n]\n",
    "    one = df1[df1.receipt_id == 1].customer_id.sum() / df1.customer_id.sum()\n",
    "    one = ['1 purhcase',one]\n",
    "    repeat = df1[df1.receipt_id >= 2].customer_id.sum() / df1.customer_id.sum()\n",
    "    repeat = ['Repeat purchasers',repeat]\n",
    "    two = df1[df1.receipt_id == 2].customer_id.sum() / df1.customer_id.sum()\n",
    "    two = ['2 purchases',two]\n",
    "    three = df1[df1.receipt_id == 3].customer_id.sum() / df1.customer_id.sum()\n",
    "    three = ['3 purchases',three]\n",
    "    four = df1[df1.receipt_id >= 4].customer_id.sum() / df1.customer_id.sum()\n",
    "    four = ['4+ purchases',four]\n",
    "    two_s = df1[df1.receipt_id == 2].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "    two_s = ['2 purchases repeaters',two_s]\n",
    "    three_s = df1[df1.receipt_id == 3].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "    three_s = ['3 purchases repeaters',three]\n",
    "    four_s = df1[df1.receipt_id >= 4].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "    four_s = ['4+ purchases repeaters',four_S]\n",
    "    avg_pc = df.delta[df['delta']>'1 days 00:00:00'].mean().days\n",
    "    avg_pc = ['Average Purchase Cycle',avg_pc]\n",
    "    med_pc = df.delta[df['delta']>'1 days 00:00:00'].median().days\n",
    "    med_pc = ['MedianPurchase Cycle',med_pc]\n",
    "    units = df.groupby('customer_id').receipt_item_id.count().to_frame().reset_index()\n",
    "    trips = df.groupby('customer_id').receipt_id.count().to_frame().reset_index()\n",
    "    trip_units = trips.merge(units,on='customer_id')\n",
    "    avg_un_tot = trip_units.receipt_item_id.mean()\n",
    "    avg_un_tot = ['Avg Units Total',avg_un_tot]\n",
    "    med_un_tot = trip_units.receipt_item_id.median()\n",
    "    med_un_tot = ['Median Units Total',med_un_tot]\n",
    "    avg_un_tot = trip_units[trip_units.receipt_id >= 2].receipt_item_id.mean()\n",
    "    avg_un_rep = ['Avg Units Repeaters',avg_un_rep]\n",
    "    med_un_rep = trip_units[trip_units.receipt_id >= 2].receipt_item_id.median()\n",
    "    med_un_rep = ['Median Units Repeaters',med_un_rep]\n",
    "\n",
    "    data_total = [n,one,repeat,two,three,four,mean_pc,median_pc,avg_un_tot,med_un_tot,avg_un_rep,med_un_rep,two_s,three_s,four_s]\n",
    "    cols=['Metric','Total Perfect Current Year']\n",
    "    trial_and_repeat = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for x in data_total:\n",
    "        d = pd.DataFrame([x],columns=cols)\n",
    "        trial_and_repeat = trial_and_repeat.append(d,ignore_index=True)\n",
    "\n",
    "    for c,v in seg_dict:\n",
    "        for v in v:\n",
    "            df = cy[cy[c] == v]\n",
    "            df['purchase_time_filled'] = pd.to_datetime(df.receipt_created_at)\n",
    "            df['delta'] = df.groupby('customer_id').purchase_time_filled.transform(pd.Series.diff)\n",
    "            df1 = df.groupby('customer_id').receipt_id.count().reset_index().groupby('receipt_id').customer_id.count().reset_index()\n",
    "            n = df1.customer_id.sum()\n",
    "            n = ['Base Size',n]\n",
    "            one = df1[df1.receipt_id == 1].customer_id.sum() / df1.customer_id.sum()\n",
    "            one = ['1 purhcase',one]\n",
    "            repeat = df1[df1.receipt_id >= 2].customer_id.sum() / df1.customer_id.sum()\n",
    "            repeat = ['Repeat purchasers',repeat]\n",
    "            two = df1[df1.receipt_id == 2].customer_id.sum() / df1.customer_id.sum()\n",
    "            two = ['2 purchases',two]\n",
    "            three = df1[df1.receipt_id == 3].customer_id.sum() / df1.customer_id.sum()\n",
    "            three = ['3 purchases',three]\n",
    "            four = df1[df1.receipt_id >= 4].customer_id.sum() / df1.customer_id.sum()\n",
    "            four = ['4+ purchases',four]\n",
    "            two_s = df1[df1.receipt_id == 2].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "            two_s = ['2 purchases repeaters',two_s]\n",
    "            three_s = df1[df1.receipt_id == 3].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "            three_s = ['3 purchases repeaters',three]\n",
    "            four_s = df1[df1.receipt_id >= 4].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "            four_s = ['4+ purchases repeaters',four_S]\n",
    "            avg_pc = df.delta[df['delta']>'1 days 00:00:00'].mean().days\n",
    "            avg_pc = ['Average Purchase Cycle',avg_pc]\n",
    "            med_pc = df.delta[df['delta']>'1 days 00:00:00'].median().days\n",
    "            med_pc = ['MedianPurchase Cycle',med_pc]\n",
    "            units = df.groupby('customer_id').receipt_item_id.count().to_frame().reset_index()\n",
    "            trips = df.groupby('customer_id').receipt_id.count().to_frame().reset_index()\n",
    "            trip_units = trips.merge(units,on='customer_id')\n",
    "            avg_un_tot = trip_units.receipt_item_id.mean()\n",
    "            avg_un_tot = ['Avg Units Total',avg_un_tot]\n",
    "            med_un_tot = trip_units.receipt_item_id.median()\n",
    "            med_un_tot = ['Median Units Total',med_un_tot]\n",
    "            avg_un_tot = trip_units[trip_units.receipt_id >= 2].receipt_item_id.mean()\n",
    "            avg_un_rep = ['Avg Units Repeaters',avg_un_rep]\n",
    "            med_un_rep = trip_units[trip_units.receipt_id >= 2].receipt_item_id.median()\n",
    "            med_un_rep = ['Median Units Repeaters',med_un_rep]\n",
    "\n",
    "            data_total = [n,one,repeat,two,three,four,mean_pc,median_pc,avg_un_tot,med_un_tot,avg_un_rep,med_un_rep,two_s,three_s,four_s]\n",
    "            col_name = v+' Current Year'\n",
    "            columns=['Metric',col_name]\n",
    "            for x in data_total:\n",
    "                d = pd.DataFrame([x],columns=columns)\n",
    "                trial_and_repeat = trial_and_repeat.merge(d,on='Metric')\n",
    "\n",
    "    df = py\n",
    "    df['purchase_time_filled'] = pd.to_datetime(df.receipt_created_at)\n",
    "    df['delta'] = df.groupby('customer_id').purchase_time_filled.transform(pd.Series.diff)\n",
    "    df1 = df.groupby('customer_id').receipt_id.count().reset_index().groupby('receipt_id').customer_id.count().reset_index()\n",
    "    n = df1.customer_id.sum()\n",
    "    n = ['Base Size',n]\n",
    "    one = df1[df1.receipt_id == 1].customer_id.sum() / df1.customer_id.sum()\n",
    "    one = ['1 purhcase',one]\n",
    "    repeat = df1[df1.receipt_id >= 2].customer_id.sum() / df1.customer_id.sum()\n",
    "    repeat = ['Repeat purchasers',repeat]\n",
    "    two = df1[df1.receipt_id == 2].customer_id.sum() / df1.customer_id.sum()\n",
    "    two = ['2 purchases',two]\n",
    "    three = df1[df1.receipt_id == 3].customer_id.sum() / df1.customer_id.sum()\n",
    "    three = ['3 purchases',three]\n",
    "    four = df1[df1.receipt_id >= 4].customer_id.sum() / df1.customer_id.sum()\n",
    "    four = ['4+ purchases',four]\n",
    "    two_s = df1[df1.receipt_id == 2].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "    two_s = ['2 purchases repeaters',two_s]\n",
    "    three_s = df1[df1.receipt_id == 3].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "    three_s = ['3 purchases repeaters',three]\n",
    "    four_s = df1[df1.receipt_id >= 4].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "    four_s = ['4+ purchases repeaters',four_S]\n",
    "    avg_pc = df.delta[df['delta']>'1 days 00:00:00'].mean().days\n",
    "    avg_pc = ['Average Purchase Cycle',avg_pc]\n",
    "    med_pc = df.delta[df['delta']>'1 days 00:00:00'].median().days\n",
    "    med_pc = ['MedianPurchase Cycle',med_pc]\n",
    "    units = df.groupby('customer_id').receipt_item_id.count().to_frame().reset_index()\n",
    "    trips = df.groupby('customer_id').receipt_id.count().to_frame().reset_index()\n",
    "    trip_units = trips.merge(units,on='customer_id')\n",
    "    avg_un_tot = trip_units.receipt_item_id.mean()\n",
    "    avg_un_tot = ['Avg Units Total',avg_un_tot]\n",
    "    med_un_tot = trip_units.receipt_item_id.median()\n",
    "    med_un_tot = ['Median Units Total',med_un_tot]\n",
    "    avg_un_tot = trip_units[trip_units.receipt_id >= 2].receipt_item_id.mean()\n",
    "    avg_un_rep = ['Avg Units Repeaters',avg_un_rep]\n",
    "    med_un_rep = trip_units[trip_units.receipt_id >= 2].receipt_item_id.median()\n",
    "    med_un_rep = ['Median Units Repeaters',med_un_rep]\n",
    "\n",
    "    data_total = [n,one,repeat,two,three,four,mean_pc,median_pc,avg_un_tot,med_un_tot,avg_un_rep,med_un_rep,two_s,three_s,four_s]\n",
    "    cols=['Metric','Total Perfect Previous Year']\n",
    "    trial_and_repeat = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for x in data_total:\n",
    "        d = pd.DataFrame([x],columns=cols)\n",
    "        trial_and_repeat = trial_and_repeat.merge(d,on='Metric')\n",
    "\n",
    "    for c,v in seg_dict:\n",
    "        for v in v:\n",
    "            df = py[py[c] == v]\n",
    "            df['purchase_time_filled'] = pd.to_datetime(df.receipt_created_at)\n",
    "            df['delta'] = df.groupby('customer_id').purchase_time_filled.transform(pd.Series.diff)\n",
    "            df1 = df.groupby('customer_id').receipt_id.count().reset_index().groupby('receipt_id').customer_id.count().reset_index()\n",
    "            n = df1.customer_id.sum()\n",
    "            n = ['Base Size',n]\n",
    "            one = df1[df1.receipt_id == 1].customer_id.sum() / df1.customer_id.sum()\n",
    "            one = ['1 purhcase',one]\n",
    "            repeat = df1[df1.receipt_id >= 2].customer_id.sum() / df1.customer_id.sum()\n",
    "            repeat = ['Repeat purchasers',repeat]\n",
    "            two = df1[df1.receipt_id == 2].customer_id.sum() / df1.customer_id.sum()\n",
    "            two = ['2 purchases',two]\n",
    "            three = df1[df1.receipt_id == 3].customer_id.sum() / df1.customer_id.sum()\n",
    "            three = ['3 purchases',three]\n",
    "            four = df1[df1.receipt_id >= 4].customer_id.sum() / df1.customer_id.sum()\n",
    "            four = ['4+ purchases',four]\n",
    "            two_s = df1[df1.receipt_id == 2].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "            two_s = ['2 purchases repeaters',two_s]\n",
    "            three_s = df1[df1.receipt_id == 3].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "            three_s = ['3 purchases repeaters',three]\n",
    "            four_s = df1[df1.receipt_id >= 4].customer_id.sum() / df1[df1.receipt_id >= 2].customer_id.sum()\n",
    "            four_s = ['4+ purchases repeaters',four_S]\n",
    "            avg_pc = df.delta[df['delta']>'1 days 00:00:00'].mean().days\n",
    "            avg_pc = ['Average Purchase Cycle',avg_pc]\n",
    "            med_pc = df.delta[df['delta']>'1 days 00:00:00'].median().days\n",
    "            med_pc = ['MedianPurchase Cycle',med_pc]\n",
    "            units = df.groupby('customer_id').receipt_item_id.count().to_frame().reset_index()\n",
    "            trips = df.groupby('customer_id').receipt_id.count().to_frame().reset_index()\n",
    "            trip_units = trips.merge(units,on='customer_id')\n",
    "            avg_un_tot = trip_units.receipt_item_id.mean()\n",
    "            avg_un_tot = ['Avg Units Total',avg_un_tot]\n",
    "            med_un_tot = trip_units.receipt_item_id.median()\n",
    "            med_un_tot = ['Median Units Total',med_un_tot]\n",
    "            avg_un_tot = trip_units[trip_units.receipt_id >= 2].receipt_item_id.mean()\n",
    "            avg_un_rep = ['Avg Units Repeaters',avg_un_rep]\n",
    "            med_un_rep = trip_units[trip_units.receipt_id >= 2].receipt_item_id.median()\n",
    "            med_un_rep = ['Median Units Repeaters',med_un_rep]\n",
    "\n",
    "            data_total = [n,one,repeat,two,three,four,mean_pc,median_pc,avg_un_tot,med_un_tot,avg_un_rep,med_un_rep,two_s,three_s,four_s]\n",
    "            col_name = v+' Previous Year'\n",
    "            columns=['Metric',col_name]\n",
    "            for x in data_total:\n",
    "                d = pd.DataFrame([x],columns=columns)\n",
    "                trial_and_repeat = trial_and_repeat.merge(d,on='Metric')\n",
    "\n",
    "    return trial_and_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basket_overview(**params):\n",
    "    \n",
    "    df = basket\n",
    "    \n",
    "    cond = df.receipt_id.isin(cy.receipt_id)\n",
    "    t_df = df[cond]\n",
    "    \n",
    "    total_spend = t_df.groupby('receipt_id').price.sum()\n",
    "    total_units = t_df.groupby('receipt_id').receipt_item_id.count()\n",
    "    avg_total_spend = total_spend.mean()\n",
    "    avg_total_spend = ['Average Trip Spend',avg_total_spend]\n",
    "    median_total_spend = total_spend.median()\n",
    "    median_total_spend = ['Median Trip Spend',median_total_spend]\n",
    "    avg_total_units = total_units.mean()\n",
    "    avg_total_units = ['Average Trip Units',avg_total_units]\n",
    "    median_total_units = total_units.median()\n",
    "    median_total_units = ['Median Trip Units',median_total_units]\n",
    "    avg_item_price = avg_total_price/avg_total_units\n",
    "    avg_item_price = ['Average Price per Item',avg_item_price]\n",
    "    median_item_price = median_total_price/median_total_units\n",
    "    median_item_price = ['Median Price per Item',median_item_price]\n",
    "        \n",
    "    brand_dollars = cy.groupby('receipt_id').price.sum()\n",
    "    avg_brand_spend = brand_dollars.mean()\n",
    "    avg_brand_spend = ['Average Brand Spend',avg_brand_spend]\n",
    "    median_brand_spend = brand_dollars.median()\n",
    "    median_brand_spend = ['Median Brand Spend',median_brand_spend]\n",
    "    brand_units = cy.groupby('receipt_id').receipt_item_id.count()\n",
    "    avg_brand_units = brand_units.mean()\n",
    "    avg_brand_units = ['Average Brand Units',avg_brand_units]\n",
    "    median_brand_units = brand_units.median()\n",
    "    median_brand_units = ['Median Brand Units',median_brand_units]\n",
    "    \n",
    "    cond_1 = cy_cat.receipt_id.isin(cy.receipt_id)\n",
    "    total_cat = cy_cat[cond_1]\n",
    "    cat_spend = total_cat.groupby('receipt_id').price.sum()\n",
    "    cat_units = total_cat.groupby('receipt_id').receipt_item_id.count()\n",
    "    avg_cat_spend = cat_spend.mean()\n",
    "    avg_cat_spend = ['Average Category Spend',avg_cat_spend]\n",
    "    median_cat_spend = cat_spend.median()\n",
    "    median_cat_spend = ['Median Category Spend',median_cat_spend]\n",
    "    avg_cat_units = cat_units.mean()\n",
    "    avg_cat_units = ['Average Category Units',avg_cat_units]\n",
    "    median_cat_units = cat_units.median()\n",
    "    median_cat_units = ['Median Category Units',median_cat_units]\n",
    "    \n",
    "    data_columns = [avg_total_spend,avg_total_units,median_total_spend,median_total_units,avg_item_price,median_item_price,avg_brand_spend,avg_brand_units,median_brand_spend,median_brand_units,avg_cat_spend,avg_cat_units,median_cat_spend,median_cat_units]\n",
    "    \n",
    "    cols = ['Metric','Total']\n",
    "    basket_overview = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    for i in data_columns:\n",
    "        d = pd.DataFrame([i],columns=cols)\n",
    "        basket_overview = basket_overview.append(d,ignore_index=True)\n",
    "    \n",
    "    for c,v in seg_dict:\n",
    "        for v in v:\n",
    "            filtered = cy[cy[c] == v]\n",
    "            b_cond = cy.receipt_id.isin(filtered.receipt_id)\n",
    "            b_df = cy[b_cond]\n",
    "            cond = df.receipt_id.isin(b_df.receipt_id)\n",
    "            t_df = df[cond]\n",
    "\n",
    "            total_spend = t_df.groupby('receipt_id').price.sum()\n",
    "            total_units = t_df.groupby('receipt_id').receipt_item_id.count()\n",
    "            avg_total_spend = total_spend.mean()\n",
    "            avg_total_spend = ['Average Trip Spend',avg_total_spend]\n",
    "            median_total_spend = total_spend.median()\n",
    "            median_total_spend = ['Median Trip Spend',median_total_spend]\n",
    "            avg_total_units = total_units.mean()\n",
    "            avg_total_units = ['Average Trip Units',avg_total_units]\n",
    "            median_total_units = total_units.median()\n",
    "            median_total_units = ['Median Trip Units',median_total_units]\n",
    "            avg_item_price = avg_total_price/avg_total_units\n",
    "            avg_item_price = ['Average Price per Item',avg_item_price]\n",
    "            median_item_price = median_total_price/median_total_units\n",
    "            median_item_price = ['Median Price per Item',median_item_price]\n",
    "\n",
    "            brand_dollars = b_df.groupby('receipt_id').price.sum()\n",
    "            avg_brand_spend = brand_dollars.mean()\n",
    "            avg_brand_spend = ['Average Brand Spend',avg_brand_spend]\n",
    "            median_brand_spend = brand_dollars.median()\n",
    "            median_brand_spend = ['Median Brand Spend',median_brand_spend]\n",
    "            brand_units = b_df.groupby('receipt_id').receipt_item_id.count()\n",
    "            avg_brand_units = brand_units.mean()\n",
    "            avg_brand_units = ['Average Brand Units',avg_brand_units]\n",
    "            median_brand_units = brand_units.median()\n",
    "            median_brand_units = ['Median Brand Units',median_brand_units]\n",
    "\n",
    "            cond_1 = cy_cat.receipt_id.isin(b_df.receipt_id)\n",
    "            total_cat = cy_cat[cond_1]\n",
    "            cat_spend = total_cat.groupby('receipt_id').price.sum()\n",
    "            cat_units = total_cat.groupby('receipt_id').receipt_item_id.count()\n",
    "            avg_cat_spend = cat_spend.mean()\n",
    "            avg_cat_spend = ['Average Category Spend',avg_cat_spend]\n",
    "            median_cat_spend = cat_spend.median()\n",
    "            median_cat_spend = ['Median Category Spend',median_cat_spend]\n",
    "            avg_cat_units = cat_units.mean()\n",
    "            avg_cat_units = ['Average Category Units',avg_cat_units]\n",
    "            median_cat_units = cat_units.median()\n",
    "            median_cat_units = ['Median Category Units',median_cat_units]\n",
    "\n",
    "            data_columns = [avg_total_spend,avg_total_units,median_total_spend,median_total_units,avg_item_price,median_item_price,avg_brand_spend,avg_brand_units,median_brand_spend,median_brand_units,avg_cat_spend,avg_cat_units,median_cat_spend,median_cat_units]\n",
    "\n",
    "            columns = ['Metrics',v]\n",
    "            for i in data_columns:\n",
    "                d = pd.DataFrame([i],columns=columns)\n",
    "                basket_overview = basket_overview.merge(d,on='Metric')\n",
    "        \n",
    "    basket_overview = basket_overview.transpose().reset_index()\n",
    "    \n",
    "    basket_overview['Average Share of Category Spend'] = basket_overview['Average Brand Spend'] / basket_overview['Average Category Spend']\n",
    "    basket_overview['Average Share of Category Units'] = basket_overview['Average Brand Units'] / basket_overview['Average Category Units']\n",
    "    basket_overview['Median Share of Category Spend'] = basket_overview['Median Brand Spend'] / basket_overview['Median Category Spend']\n",
    "    basket_overview['Median Share of Category Units'] = basket_overview['Median Brand Units'] / basket_overview['Median Category Units']\n",
    "        \n",
    "    return basket_overview\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basket_adjacency(**params):\n",
    "    \n",
    "    brand_basket_adjacency = exec_presto(sql.cat_brand_trip.format(**params))\n",
    "    category_basket_adjacency = exec_presto(sql.cat_category_trip.format(**params))\n",
    "    product_basket_adjacency = exec_presto(sql.cat_product_trip.format(**params))\n",
    "    \n",
    "    df = basket\n",
    "    cond = df.receipt_id.isin(cy.receipt_id)\n",
    "    t_df = df[cond]\n",
    "    \n",
    "    brand_df = t_df.groupby('brand_name')\n",
    "    brand_df = brand_df.agg({'receipt_id': 'nunique'})\n",
    "    brand_df = brand_df.reset_index()\n",
    "    brand_df['Total'] = brand_df['receipt_id']/len(t_df.receipt_id.unique()) \n",
    "    brand_df = [['brand_name','Total']]\n",
    "    brand_basket_adjacency = brand_basket_adjacency.merge(brand_df,on='brand_name',how='inner')\n",
    "    del brand_df\n",
    "    \n",
    "    category_df = t_df.groupby('category_name')\n",
    "    category_df = category_df.agg({'receipt_id': 'nunique'})\n",
    "    category_df = category_df.reset_index()\n",
    "    category_df['Total'] = category_df['receipt_id']/len(t_df.receipt_id.unique()) \n",
    "    category_df = [['category_name','Total']]\n",
    "    category_basket_adjacency = category_basket_adjacency.merge(category_df,on='category_name',how='inner')\n",
    "    del cat_df\n",
    "    \n",
    "    product_df = t_df.groupby('category_name')\n",
    "    product_df = product_df.agg({'receipt_id': 'nunique'})\n",
    "    product_df = product_df.reset_index()\n",
    "    product_df['Total'] = product_df['receipt_id']/len(t_df.receipt_id.unique()) \n",
    "    product_df = [['product_name','Total']]\n",
    "    product_basket_adjacency = product_basket_adjacency.merge(product_df,on='product_name',how='inner')\n",
    "    del product_df\n",
    "    del t_df\n",
    "    \n",
    "    for c,v in seg_dict.iteritems():\n",
    "        for v in v:\n",
    "            seg = cy[cy[c] == v]\n",
    "            cond = df.receipt_id.isin(seg.receipt_id)\n",
    "            s_df = df[cond]\n",
    "            del seg\n",
    "            brand_df1 = s_df.groupby('brand_name')\n",
    "            brand_df1 = brand_df1.agg({'receipt_id': 'nunique'})\n",
    "            brand_df1 = brand_df1.reset_index()\n",
    "            col_name = v\n",
    "            brand_df1[col_name] = brand_df1['receipt_id']/len(s_df.receipt_id.unique()) \n",
    "            brand_df1 = [['brand_name',col_name]]\n",
    "\n",
    "            category_df1 = s_df.groupby('category_name')\n",
    "            category_df1 = category_df.agg({'receipt_id': 'nunique'})\n",
    "            category_df1 = category_df.reset_index()\n",
    "            category_df1[col_name] = category_df1['receipt_id']/len(s_df.receipt_id.unique()) \n",
    "            category_df1 = [['category_name',col_name]]\n",
    "\n",
    "            product_df1 = s_df.groupby('category_name')\n",
    "            product_df1 = product_df1.agg({'receipt_id': 'nunique'})\n",
    "            product_df1 = product_df1.reset_index()\n",
    "            product_df1[col_name] = product_df1['receipt_id']/len(s_df.receipt_id.unique()) \n",
    "            product_df1 = [['product_name',col_name]]\n",
    "            \n",
    "            brand_basket_adjacency = brand_basket_adjacency.merge(brand_df1,on='brand_name',how='outer')\n",
    "            category_basket_adjacency = category_basket_adjacency.merge(category_df1,on='category_name',how='outer')\n",
    "            product_basket_adjacency = product_basket_adjacency.merge(product_df1,on='product_name',how='outer')\n",
    "    \n",
    "    del brand_df1\n",
    "    del category_df1\n",
    "    del product_df1\n",
    "    del s_df\n",
    "    \n",
    "    brand_basket_adjacency['Total Category Index'] = (brand_basket_adjacency['Total']/brand_basket_adjacency['Category Benchmark'])*100\n",
    "    category_basket_adjacency['Total Category Index'] = (category_basket_adjacency['Total']/category_basket_adjacency['Category Benchmark'])*100\n",
    "    product_basket_adjacency['Total Category Index'] = (product_basket_adjacency['Total']/product_basket_adjacency['Category Benchmark'])*100\n",
    "    \n",
    "    items = seg_dict.values()\n",
    "    \n",
    "    for x in items:\n",
    "    \n",
    "        cat_name = x+' Category Index'\n",
    "        brand_basket_adjacency[cat_name] = (brand_basket_adjacency[x]/brand_basket_adjacency['Category Benchmark'])*100\n",
    "        category_basket_adjacency[cat_name] = (category_basket_adjacency[x]/category_basket_adjacency['Category Benchmark'])*100\n",
    "        product_basket_adjacency[cat_name] = (product_basket_adjacency[x]/product_basket_adjacency['Category Benchmark'])*100\n",
    "\n",
    "        total_name = x+'Total Brand Index'\n",
    "        brand_basket_adjacency[total_name] = (brand_basket_adjacency[x]/brand_basket_adjacency['Total'])*100\n",
    "        category_basket_adjacency[total_name] = (category_basket_adjacency[x]/category_basket_adjacency['Total'])*100\n",
    "        category_basket_adjacency[total_name] = (product_basket_adjacency[x]/product_basket_adjacency['Total'])*100\n",
    "    \n",
    "    \n",
    "    return brand_basket_adjacency, category_basket_adjacency, product_basket_adjacency\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basket_product_overlap(**params):\n",
    "\n",
    "    receipt_overlap = cy.groupby('global_product_name')\n",
    "    receipt_overlap = receipt_overlap.agg({'receipt_id': 'nunique'})\n",
    "    receipt_overlap = receipt_overlap.reset_index()\n",
    "    receipt_overlap = receipt_overlap[['global_product_name','overlap']]\n",
    "    receipt_overlap['overlap'] = receipt_overlap['receipt_id'] / len(receipt_overlap.receipt_id.unique())\n",
    "    columns = ['global_product_name','Total']\n",
    "    receipt_overlap.columns = cols\n",
    "    \n",
    "    products = list(cy.global_product_name.unique())\n",
    "    \n",
    "    for i in products:\n",
    "        df = cy\n",
    "        product = df[df['global_product_name'] == i]\n",
    "        cond = df.receipt_id.isin(product.receipt_id)\n",
    "        data = df[cond]\n",
    "        data = data.groupby('global_product_name')\n",
    "        data = data.agg({'receipt_id': 'nunique'})\n",
    "        data = data.reset_index()\n",
    "        data['overlap'] = data['receipt_id'] / len(data[data['global_product_name']==i].receipt_id.unique())\n",
    "        data = data[['global_product_name','overlap']]\n",
    "        name = i+' Overall'\n",
    "        cols = ['global_product_name',name]\n",
    "        data.columns = cols\n",
    "        \n",
    "        receipt_overlap = receipt_overlap.merge(data,on='global_product_name',how='outer')\n",
    "    \n",
    "    del data\n",
    "    del product\n",
    "    del df\n",
    "    \n",
    "    for c,v in seg_dict:\n",
    "        for v in v:\n",
    "                for i in products:\n",
    "                    df = cy\n",
    "                    product = df[(df['global_product_name'] == i) & (df[c] == v)]\n",
    "                    cond = df.receipt_id.isin(product.receipt_id)\n",
    "                    data = df[cond]\n",
    "                    data = data.groupby('global_product_name')\n",
    "                    data = data.agg({'receipt_id': 'nunique'})\n",
    "                    data = data.reset_index()\n",
    "                    data['overlap'] = data['receipt_id'] / len(data[(data['global_product_name']==i) & (data[c] == v)].receipt_id.unique())\n",
    "                    data = data[['global_product_name','overlap']]\n",
    "                    name = v+'-'+i\n",
    "                    cols = ['global_product_name',name]\n",
    "                    data.columns = cols\n",
    "                    receipt_overlap = receipt_overlap.merge(data,on='global_product_name',how='outer')\n",
    "    del data\n",
    "    del product\n",
    "    del df\n",
    "    \n",
    "    return receipt_overlap\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_overlap(**params):\n",
    "    \n",
    "    overlap_dict = {}\n",
    "    for c,v in seg_dict:\n",
    "        for v in v:\n",
    "            name = v+' Overlap'\n",
    "            filt_df = cy[cy[c] == v]\n",
    "            cond = cy.customer_id.isin(filt_df.customer_id)\n",
    "            df = filt_df[cond]\n",
    "            df = df.groupby(c)\n",
    "            df = df.agg({'customer_id': 'nunique'})\n",
    "            df = data.reset_index()\n",
    "            df['overlap'] = df['customer_id'] / len(df[df[c]==v].customer_id.unique())\n",
    "            df = df[[c,'overlap']]\n",
    "            cols = [c,name]\n",
    "            df.columns = cols\n",
    "            overlap_dict[v] = df\n",
    "    \n",
    "    merged_overlap_dict = {}\n",
    "    for k,v in seg_dict.items():\n",
    "        n = seg_dict[k]\n",
    "        temp_dict = {}\n",
    "        for i in n:\n",
    "            d = overlap_dict[i]\n",
    "            temp_dict[i] = d\n",
    "            loop_count = 1\n",
    "            for i in n:\n",
    "                df1 = temp_dict[i]\n",
    "                if loop_count == 1:\n",
    "                    data = df1\n",
    "                    loop_count = loop_count+1\n",
    "                else:\n",
    "                    data = data.merge(df1,on=k,how='outer')\n",
    "        merged_overlap_dict[k] = data\n",
    "    overlap_df = pd.DataFrame()\n",
    "    dfs_to_concat = list(merged_overlap_dict.keys())\n",
    "    loop_countt = 1\n",
    "    for i in dfs_to_concat:\n",
    "        d = merged_overlap_dict[i]\n",
    "        overlap_df = overlap_df.concat(d,axis=1)\n",
    "    \n",
    "    return overlap_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sa(segment_columns,\n",
    "       segment_table: str = 'segment_table',\n",
    "       name: str = 'project_name',\n",
    "       segment_py_table: str = 'segment_py_table',\n",
    "       category_table: str = 'category_table',\n",
    "       category_py_table: str = 'category_py_table',\n",
    "       active_table: str = 'active_table',\n",
    "       active_py_table: str = 'active_py_table'):\n",
    "\n",
    "    params = {}\n",
    "\n",
    "    params['segment_columns'] = segment_columns\n",
    "    params['segment_table'] = segment_table\n",
    "    params['segment_py_table'] = segment_py_table\n",
    "    params['category_table'] = category_table\n",
    "    params['category_py_table'] = category_py_table\n",
    "    params['active_table'] = active_table\n",
    "    params['active_py_table'] = active_py_table\n",
    "    params['name'] = name\n",
    "\n",
    "    current_year_brand = exec_presto(sql.cy_brand.format(**params))\n",
    "    past_year_brand = exec_presto(sql.cy_brand.format(**params))\n",
    "\n",
    "    params['cy'] = current_year_brand\n",
    "    params['py'] = past_year_brand\n",
    "    \n",
    "    cy = params['cy']\n",
    "    py = params['py']\n",
    "    \n",
    "    seg_dict={}\n",
    "    for i in params['segment_columns']:\n",
    "        c = list(cy[i].unique())\n",
    "        p = list(py[i].unique())\n",
    "        common = set(c) - (set(c) - set(p))\n",
    "        seg_dict[i] = common\n",
    "\n",
    "    params['seg_dict'] = seg_dict\n",
    "\n",
    "    total_pop_cy = exec_presto(sql.cy_total_pop.format(**params))\n",
    "    total_pop_py = exec_presto(sql.py_total_pop.format(**params))\n",
    "    total_pop_py = total_pop_py.total.sum()\n",
    "    total_pop_cy = total_pop_cy.total.sum()\n",
    "    \n",
    "\n",
    "    params['total_pop_cy'] = total_pop_cy\n",
    "    params['total_pop_py'] = total_pop_py\n",
    "\n",
    "    tabs_data: list = []\n",
    "    vol = volumetrics(**params)\n",
    "    tabs_data.append([volume])\n",
    "    \n",
    "    del params['total_pop_cy']\n",
    "    del params['total_pop_py']\n",
    "    \n",
    "    try_repeat = trial_repeat(**params)\n",
    "    tabs_data.append([try_repeat])\n",
    "    \n",
    "    params['volume_overview'] = vol\n",
    "    \n",
    "    cat_cy = exec_presto(sql.cy_cat.format(**params))\n",
    "    params['cy_cat'] = cat_cy\n",
    "    del params['py']\n",
    "    \n",
    "    loyalty = brand_loyalty(**params)\n",
    "    tabs_data.append([loyalty])\n",
    "    \n",
    "\n",
    "    basket = exec_presto(sql.basket_data.format(**params))\n",
    "    cat_names = exec_presto(sql.category_names)\n",
    "    brand_names = exec_presto(sql.brand_names)\n",
    "    product_names = exec_presto(sql.product_names)\n",
    "    basket = basket.merge(cat_names,on=secondary_category_id,how='left')\n",
    "    basket = basket.merge(brand_names,on=brand_id,how='left')\n",
    "    basket = basket.merge(product_names,on=global_product_id,how='left')\n",
    "    params['basket'] = basket\n",
    "    \n",
    "    del cat_names\n",
    "    del brand_names\n",
    "    del product_names\n",
    "    \n",
    "    \n",
    "    trip_overview = basket_overview(**params)\n",
    "    tabs_data.append([trip_overview])    \n",
    "    \n",
    "    trip_adjacency = list(basket_adjacency(**params))\n",
    "    tabs_data.append(trip_adjacency)\n",
    "    \n",
    "    trips_overlap = basket_product_overlap.format(**params)\n",
    "    tabs_data.append([trip_overlap])\n",
    "    \n",
    "    segment_overlap = total_overlap(**params)\n",
    "    tabs_list.append([segment_overlap])\n",
    "        \n",
    "    \n",
    "    xlname = '{name}_Shopper_Analysis.xlsx'.format(**params)\n",
    "\n",
    "    sheet_names = [\"Volumentrics\",\n",
    "                   \"Trial & Repeat\",\n",
    "                   \"Brand Loyalty\",\n",
    "                   \"Basket Overview\",\n",
    "                   \"Basket Adjacency\",\n",
    "                   \"Trip Overlap\",\n",
    "                   \"Overall Overlap\",\n",
    "                   \"Purchase History\"]\n",
    "\n",
    "    dump_to_excel(xlname, tabs_data, sheet_names=sheet_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-21 14:57:06] Request ID is: 10465589-1-1624309026.087. Please share it with Qubole Support team for any assistance\n",
      "The Qubole application experienced an issue in processing this request and it was not successful. If you would like this issue investigated, please provide error code 90173f23-8007-4a66-ac84-6eb3f8291eca and precise details in a Qubole support ticket for further analysis.\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "The Qubole application experienced an issue in processing this request and it was not successful. If you would like this issue investigated, please provide error code 90173f23-8007-4a66-ac84-6eb3f8291eca and precise details in a Qubole support ticket for further analysis.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServerError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-414d153f95d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegment_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agajeski.whole_earth_portfolio_analysis'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegment_py_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agajeski.whole_earth_portfolio_analysis_py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agajeski.sugar_sweetener_category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategory_py_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agajeski.sugar_sweetener_category_py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactive_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agajeski.active_feb19_feb20'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactive_py_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'agajeski.active_feb20_feb21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-19d3fdb87296>\u001b[0m in \u001b[0;36msa\u001b[0;34m(segment_columns, segment_table, name, segment_py_table, category_table, category_py_table, active_table, active_py_table)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcurrent_year_brand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexec_presto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_brand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mpast_year_brand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexec_presto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcy_brand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-c97db2a1a7c3>\u001b[0m in \u001b[0;36mexec_presto\u001b[0;34m(query, return_data, cluster, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexec_presto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'presto-consumer-insights-dev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_presto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\\\N'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ds_util/qubole.py\u001b[0m in \u001b[0;36mrun_presto\u001b[0;34m(query, job_name, config_path, cluster, return_data, include_col_names, max_retry, max_workers, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         )\n\u001b[1;32m    510\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m         result = __execute_qubole(job_type=\"presto\", job=query,\n\u001b[0m\u001b[1;32m    512\u001b[0m                     \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'QUBOLE_TOKEN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0mcluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_obj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ds_util/qubole.py\u001b[0m in \u001b[0;36m__execute_qubole\u001b[0;34m(job_type, job, job_name, token, cluster, return_data, return_obj, include_col_names, max_retry, code_lang, spark_conf, spark_cli, sub_command, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__execute_hive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mjob_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"presto\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__execute_presto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mjob_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spark\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__execute_spark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspark_cli\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark_cli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/ds_util/qubole.py\u001b[0m in \u001b[0;36m__execute_presto\u001b[0;34m(token, query, job_name, cluster, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \"\"\"\n\u001b[1;32m    126\u001b[0m     \u001b[0mQubole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPrestoCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__execute_shell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/qds_sdk/commands.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrest_entity_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/qds_sdk/connection.py\u001b[0m in \u001b[0;36mf_retry\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mmtries\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mExceptionToCheck\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"retry\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/qds_sdk/connection.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, data)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlwaysRetryWithDelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlwaysRetryWithDelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/qds_sdk/connection.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, req_type, path, data, params)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_call_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/qds_sdk/connection.py\u001b[0m in \u001b[0;36m_api_call_raw\u001b[0;34m(self, req_type, path, data, params)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/qds_sdk/connection.py\u001b[0m in \u001b[0;36m_handle_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServerError\u001b[0m: The Qubole application experienced an issue in processing this request and it was not successful. If you would like this issue investigated, please provide error code 90173f23-8007-4a66-ac84-6eb3f8291eca and precise details in a Qubole support ticket for further analysis."
     ]
    }
   ],
   "source": [
    "sa(segment_columns=['segment'],segment_table='agajeski.whole_earth_portfolio_analysis',segment_py_table='agajeski.whole_earth_portfolio_analysis_py',category_table='agajeski.sugar_sweetener_category',category_py_table='agajeski.sugar_sweetener_category_py',active_table='agajeski.active_feb19_feb20',active_py_table='agajeski.active_feb20_feb21',name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cy_brand = \"\"\"\n",
    "select\n",
    "*\n",
    "from {segment_table}\n",
    "\"\"\"\n",
    "py_brand = \"\"\"\n",
    "select\n",
    "*\n",
    "from {segment_py_table}\n",
    "\"\"\"\n",
    "\n",
    "cy_cat = \"\"\"\n",
    "select\n",
    "*\n",
    "from {category_table}\n",
    "\"\"\"\n",
    "py_cat = \"\"\"\n",
    "select\n",
    "*\n",
    "from {category_py_table}\n",
    "\"\"\"\n",
    "\n",
    "cy_total_pop = \"\"\"\n",
    "select\n",
    "count(distinct customer_id) as total\n",
    "from {active_table}\n",
    "\"\"\"\n",
    "\n",
    "py_total_pop = \"\"\"\n",
    "select\n",
    "count(distinct customer_id) as total\n",
    "from {active_py_table}\n",
    "\"\"\"\n",
    "\n",
    "basket_data = \"\"\"\n",
    "select\n",
    "f.customer_id,\n",
    "f.receipt_id,\n",
    "f.brand_id,\n",
    "f.global_product_id,\n",
    "f.receipt_item_id,\n",
    "f.secondary_category_id,\n",
    "case when ri.ext_price is not null and ri.quantity > 1 then ri.ext_price\n",
    "when ri.ext_price is null then ri.price\n",
    "else ri.ext_price\n",
    "end as \"price\"\n",
    "from vw_fact_customer_receipt_item_procuct_details f\n",
    "inner join {segment_table} s on f.receipt_id = s.receipt_id\n",
    "where\n",
    "((ri.ext_price is not null and ri.quantity > 1 and ri.ext_price > 0 and ri.ext_price < 50) or (ri.ext_price is null and ri.price > 0 and ri.price < 50) or (ri.ext_price > 0 and ri.ext_price < 50))\n",
    "and f.verified is null\n",
    "\"\"\"\n",
    "\n",
    "brand_names = \"\"\"\n",
    "select\n",
    "distinct name as brand_name,\n",
    "id as brand_id\n",
    "from vw_brands\n",
    "\"\"\"\n",
    "product_names = \"\"\"\n",
    "select\n",
    "distinct name as product_name,\n",
    "id as global_product_id\n",
    "from vw_global_products\n",
    "\"\"\"\n",
    "\n",
    "category_names = \"\"\"\n",
    "select\n",
    "distinct id as secondary_category_id,\n",
    "name as category_name\n",
    "from vw_product_categories\n",
    "\"\"\"\n",
    "\n",
    "cat_brand_trip = \"\"\"\n",
    "with total as(\n",
    "select\n",
    "count(distinct receipt_id) as total\n",
    "from {category_table})\n",
    "select distinct b.name as brand_name,\n",
    "count(distinct f.receipt_id)/t.total as 'Category Benchmark'\n",
    "from vw_fact_customer_receipt_item_product_details f,total t\n",
    "join vw_brands b on b.id = f.brand_id\n",
    "where\n",
    "f.receipt_id in (select distinct receipt_id\n",
    "from {category_table})\n",
    "and f.verified is null\n",
    "group by 1\n",
    "order by 2 desc\n",
    "\"\"\"\n",
    "\n",
    "cat_category_trip = \"\"\"\n",
    "with total as(\n",
    "select\n",
    "count(distinct receipt_id) as total\n",
    "from {category_table})\n",
    "select distinct b.name as category_name,\n",
    "count(distinct f.receipt_id)/t.total as 'Category Benchmark'\n",
    "from vw_fact_customer_receipt_item_product_details f, total t\n",
    "join vw_product_categories b on b.id = f.secondary_category_id\n",
    "where\n",
    "f.receipt_id in (select distinct receipt_id\n",
    "from {category_table})\n",
    "and f.verified is null\n",
    "group by 1\n",
    "order by 2 desc\n",
    "\"\"\"\n",
    "\n",
    "cat_product_trip = \"\"\"\n",
    "with total as(\n",
    "select\n",
    "count(distinct receipt_id) as total\n",
    "from {category_table})\n",
    "select distinct b.name as product_name,\n",
    "count(distinct f.receipt_id)/t.total as 'Category Benchmark'\n",
    "from vw_fact_customer_receipt_item_product_details f,total t\n",
    "join vw_global_products b on b.id = f.global_product_id\n",
    "where\n",
    "f.receipt_id in (select distinct receipt_id\n",
    "from {category_table})\n",
    "and f.verified is null\n",
    "group by 1\n",
    "order by 2 desc\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
